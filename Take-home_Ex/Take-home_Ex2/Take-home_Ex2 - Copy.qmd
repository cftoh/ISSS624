---
title: "Take-Home Exercise 2"
date: "6 December 2023"
date-modified:  "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning:  false
editor: visual
---

# Take-home Exercise 2: Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows

## Motivation and Objective

This take-home exercise is motivated by two main reasons. Firstly, despite increasing amounts of open data available for public consumption, there has not been significant practice research carried out to show how these disparate data sources can be integrated, analysed, and modelled to support policy making decisions.

Secondly, there is a general lack of practical research to show how geospatial data science and analysis (GDSA) can be used to support decision-making.

Hence, your task for this take-home exercise is to conduct a case study to demonstrate the potential value of GDSA to integrate publicly available data from multiple sources for building a spatial interaction models to determine factors affecting urban mobility patterns of public bus transit.

## The Data

### Open Government Data

For the purpose of this assignment, data from several open government sources will be used:

-   *Passenger Volume by Origin Destination Bus Stops*, *Bus Stop Location*, *Train Station* and *Train Station Exit Point*, just to name a few of them, from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

-   *Master Plan 2019 Subzone Boundary*, *HDB Property Information*, *School Directory and Information* and other relevant data from [Data.gov.sg](https://beta.data.gov.sg/).

### Specially collected data

-   Businesses, retail and services, leisure and recreation, etc geospatial data sets assemble by course instructor. (Refer to eLearn)

## The Task

### Geospatial Data Science

-   Derive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf).

-   With reference to the time intervals provided in the table below, construct an O-D matrix of commuter flows for a time interval of your choice by integrating *Passenger Volume by Origin Destination Bus Stops* and *Bus Stop Location* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html). The O-D matrix must be aggregated at the analytics hexagon level

    | Peak hour period             | Bus tap on time |
    |------------------------------|-----------------|
    | Weekday morning peak         | 6am to 9am      |
    | Weekday afternoon peak       | 5pm to 8pm      |
    | Weekend/holiday morning peak | 11am to 2pm     |
    | Weekend/holiday evening peak | 4pm to 7pm      |

-   Display the O-D flows of the passenger trips by using appropriate geovisualisation methods (not more than 5 maps).

-   Describe the spatial patterns revealed by the geovisualisation (not more than 100 words per visual).

-   Assemble at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.

-   Compute a distance matrix by using the analytical hexagon data derived earlier.

### Spatial Interaction Modelling

-   Calibrate spatial interactive models to determine factors affecting urban commuting flows at the selected time interval.

-   Present the modelling results by using appropriate geovisualisation and graphical visualisation methods. (Not more than 5 visuals)

-   With reference to the Spatial Interaction Model output tables, maps and data visualisation prepared, describe the modelling results. (not more than 100 words per visual).

## FIRST STEP

Load in necessary packages:

```{r}
pacman::p_load(tmap, sf, sp, DT, stplanr,
               performance, reshape2,
               ggpubr, tidyverse)
```

As we are aware, there is an increasing amounts of open data available, but there has not been significant practice research carried out to show how these disparate data sources can be integrated, analysed, and modelled to support policy making decisions. In this section I will be performing integration of various data sources.

I will first check the various database selected to see how is it possible to build a hollistic database.

## Data Import, Extraction, Processing

### Geospatial Data - Bus Stop

```{r}
BusStop <- st_read(dsn="data/geospatial",
                  layer="BusStop")%>%
  st_transform(crs = 3414)
```

I see that BusStop is a point geometry SF with "BUS_STOP_N", "BUS_ROOF_N", "LOC_DESC" and its geometry.

```{r}
MPSZ <- st_read(dsn="data/geospatial",                   
                layer="MPSZ-2019")%>%   
  st_transform(crs = 3414)
```

I see that MPSZ is a Multipolygon geometry SF with "SUBZONE_N", "SUBZONE_C", "PLN_AREA_N", "PLN_AREA_C", "REGION_N", "REGION_C" and its geometry.

#### Creating Hexagon

Traffic Analysis Zone (TAZ)

Traffic analysis zones are universally used in travel demand modelling to represent the spatial distribution of trip1 origins and destinations, as well as the population, employment and other spatial attributes that generate or otherwise influence travel demand. The urban area is divided into a set of mutually exclusive and collectively exhaustive zones. While travel actually occurs from one point in the urban region to another, all trip origins and destinations in a travel demand model are represented at the spatially aggregate level of the movement from an origin zone to a destination zone. These movements are further aggregated within network assignment models as originating and ending at single points within the origin and destination zones -- the zone centroids.

As we should derive an analytical hexagon data of 325m (this distance is the perpendicular distance between the centre of the hexagon and its edges) to represent the TAZ,

Per the documentation of st_make_grid:

*cellsize* is *numeric of length 1 or 2 with target cellsize: ..for hexagonal cells the distance between opposite edges (edge length is cellsize/sqrt(3)). A length units object can be passed, or an area unit object with area size of the square or hexagonal cell.*

In this case, the distance between opposite edges should be 325m \* 2. And the length of hexagon should be 325m.

```{r}
BusStop_hexagon_grid = st_make_grid(BusStop, 325, what = "polygons", square = FALSE)

BusStop_hexagon_sf = st_sf(geometry = BusStop_hexagon_grid) %>%
  # add grid ID
  mutate(grid_id = 1:length(lengths(BusStop_hexagon_grid)))
```

We will next use `st_intersection()` for point and polygon overlay, to combine the data sets. This will provide us with output in point sf object.

```{r}
BusStop_hexagon <- st_intersection(BusStop_hexagon_sf, BusStop) %>%   
  select(1,2,4) %>%   
  st_drop_geometry()
```

```{r}
MPSZ_hexagon <- st_intersection(BusStop_hexagon_sf, MPSZ)  %>%  
  select(1:3) 

BusStop_MPSZ_hexagon <- left_join(BusStop_hexagon,MPSZ_hexagon,
                                  by = "grid_id")

```

Note this *BusStop_MPSZ_hexagon* only contain the hexagon which has got bus stop within the area.

```{r}
write_rds(BusStop_hexagon, "data/rds/BusStop_hexagon.rds")
```

[Performing the Relational Join (to update attribute table of one geospatial with another aspatial data set)]{.underline}

Now we will next combine this onto our our *odbs_peak* data frame which shows the total number of trips from particular bus stop during peak hour.

#### Aspatial Data

Next we import the Aspatial Data of PASSENGER VOLUME BY ORIGIN DESTINATION BUS STATIONS, downloaded via API (postman GET) from Data Mall LTA. For the purpose of this exercise the Aug 2023 Data will be used.

```{r}
OD_bus <- read_csv("data/aspatial/origin_destination_bus_202308.csv")
#non-spatial data with no geometry features
```

```{r}
OD_bus$ORIGIN_PT_CODE <- as.factor(OD_bus$ORIGIN_PT_CODE)
OD_bus$DESTINATION_PT_CODE <- as.factor(OD_bus$DESTINATION_PT_CODE) 
```

Noted that the aspatial data for bus has total of 7 columns YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS.

For the purpose of this exercise, we only look at those Bus tap on time on **Weekday morning peak, between 6am to 9am.**

```{r}
OD_bus_peak <- OD_bus %>% 
  filter(DAY_TYPE == "WEEKDAY" & 
           (TIME_PER_HOUR >=6 & TIME_PER_HOUR <=9))  
summary(OD_bus_peak)
```

## Computing the distance matrix

We use the spDists() coz faster.

```{r}
BusStop_hexagon_sp <- as(BusStop_hexagon_sf, "Spatial")
```

```{r}
dist <- spDists(BusStop_hexagon_sp,                  
                longlat = FALSE)  
#because or subzone is already svr21. Otherwise it will treat data as x and y, then calculate great circle distance.  
head(dist, n=c(10, 10)) #only list first 10 col and 10 rows
```

Notice that the output *dist* is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes.

### Labelling column and row headers of a distance matrix

First, we will create a list sorted according to the the distance matrix by planning sub-zone code.

```{r}
grid <- BusStop_hexagon_sf$grid_id
```

Next we will attach `SUBZONE_C` to row and column for distance matrix matching ahead

```{r}
colnames(dist) <- paste0(grid) 
rownames(dist) <- paste0(grid)
```

### Pivoting distance value by SUBZONE_C

Next, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.

```{r}
distPair <- melt(dist) %>% 
  rename(dist = value)
head(distPair, 10)
```

*Note that melt() is a old reshape tool function, that take dist matrix and convert it to long table, 1. origin, 2. destination, 3. distance matrix*

Notice that the within zone distance is 0.

### Updating intra-zonal distances

Now I am going to append a constant value to replace the intra-zonal distance of 0, first select and find out the minimum value of the distance by using `summary()`.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)

```

```{r}
distPair %>%   
  filter(dist > 0) %>%   
  summary()
```

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

## Preparing flow data

Note that although I would want to keep all the fields intact as I wasnt sure what are the data I need for the next steps. It is taking too much processing power and space, so i will summarize and aggregate the value of selected time.

```{r}
BusStop_Trips <- left_join(OD_bus_peak, BusStop_hexagon, #the left join is so to get grid ID from hexagon file
                      by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  drop_na() %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_GRID = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE
         )%>%
  group_by(ORIGIN_GRID, ORIGIN_BS, DESTIN_BS) %>% 
  summarize(TRIPS = sum(TOTAL_TRIPS))

```

But there isn't grid ID for my **destination** so i will now do the following to get complete picture:

```{r}
BusStop_Trips <- BusStop_Trips %>%
  left_join(BusStop_hexagon, #the left join is so to get grid ID from hexagon file
                      by = c("DESTIN_BS" = "BUS_STOP_N")) %>%
  drop_na() %>%
    rename(DESTIN_GRID = grid_id)%>%
  select(1,2,5,3,4)


```

```{r}
BusStop_Trips <- unique(BusStop_Trips)
```

## Visualising Spatial Interaction

### Separating intra-flow from passenger volume df

To add three new fields in BusStop_Trips dataframe, that is to be used for flow.

```{r}
str(BusStop_Trips)
```

This above checks show that my ORIGIN_BS column is chr, therefore i will now convert it to factor:

```{r}
BusStop_Trips$ORIGIN_BS <- as.factor(BusStop_Trips$ORIGIN_BS)
```

```{r}
BusStop_Trips$FlowNoIntra <- ifelse(
  BusStop_Trips$ORIGIN_GRID == BusStop_Trips$DESTIN_GRID, 
  0, BusStop_Trips$TRIPS)
BusStop_Trips$offset <- ifelse(
  BusStop_Trips$ORIGIN_GRID == BusStop_Trips$DESTIN_GRID, 
  0.000001, 1)
```

### Combining passenger volume data with distance value

```{r}
BusStop_Trips1 <- BusStop_Trips %>%
  left_join (distPair,
             by = c("ORIGIN_GRID" = "orig",
                    "DESTIN_GRID" = "dest"))

```

```{r}
summary(BusStop_Trips1)
```

From the summary above, it is noted that there are some origin and destination bus stops within the same hexagon grid. For the purpose of this exercise we will exclude them, as the aim is to find out the interozonal (hexagon) flow.

```{r}
BusStop_Trips2 <- BusStop_Trips1 %>%
  filter(dist>0)
summary(BusStop_Trips2)
```

Now we see the minimum is 325, which is the the perpendicular distance between the centre of the hexagon and its edges (next hexagon).

### Visualization for the TOTAL TRIPS taken at Origin and Destination hexagon area

```{r}
origin_density_map <- left_join(BusStop_hexagon_sf, BusStop_Trips1,
                                by =c("grid_id" = "ORIGIN_GRID")) %>%
  drop_na() %>%
  rename(ORIGIN_GRID = grid_id) %>%
  group_by(ORIGIN_GRID) %>% 
  summarize(TOTAL_TRIPS = sum(TRIPS), AVERAGE_DIST = weighted.mean(dist, w = TRIPS))

destin_density_map <- left_join(BusStop_hexagon_sf, BusStop_Trips1,
                                by =c("grid_id" = "DESTIN_GRID")) %>%
  drop_na() %>%
  rename(DESTIN_GRID = grid_id) %>%
  group_by(DESTIN_GRID) %>% 
  summarize(TOTAL_TRIPS = sum(TRIPS), AVERAGE_DIST = weighted.mean(dist, w = TRIPS))
```

We will just narrow down to look at **number of trips above 100k** during this period.

```{r}
tmap_mode("view")
#tmap_options(check.and.fix = TRUE)
map_honeycomb = tm_shape(origin_density_map %>%
                         filter(TOTAL_TRIPS>100000)) +
  tm_fill(
    col = "TOTAL_TRIPS",
    palette = "Reds",
    style = "cont",
    title = "Number of Trips by Origin Bus Stop within the Area",
    alpha = 0.4,
    popup.vars = c("Number of TRIPS: " = "TOTAL_TRIPS"),
    popup.format = list(TOTAL_TRIPS = list(format = "f", digits = 0))) +
  tm_borders(col = "grey40", lwd = 0.7)+
  tm_scale_bar()

map_honeycomb1 = tm_shape(destin_density_map %>%
                         filter(TOTAL_TRIPS>100000))+ 
  tm_fill("TOTAL_TRIPS", 
          style = "cont", 
          palette = "Reds",
          title = "Number of Trips by Destination Bus Stop within the Area",
          alpha = 0.4,
          popup.vars = c("Number of TRIPS: " = "TOTAL_TRIPS"),
          popup.format = list(TOTAL_TRIPS = list(format = "f", digits = 0))) +
  tm_borders(col = "grey40", lwd = 0.7)+
  tm_scale_bar()

tmap_arrange(map_honeycomb, map_honeycomb1, asp=2, ncol=2)
```

[Insights]{.underline}

It is quite surprising to see that there isn't much alight activity amongst the bus stataion in CBD area, given that this is **Weekday morning peak, between 6am to 9am.** However, having another thought, this timing is probably more relevant to students going to school (since classes start early from 7 to 8am). Likely the CBD crowd only kicks in from 8-9am, which is significantly lesser in comparison to the whole dataset. We can dive down further (segregate the timing e.g. do one 6-8, one 7-9, to see any difference in results) as the next project.

An interesting sight is that grid_id 5700 has high number of BOTH incoming and outgoing traffic, as reflected by the 301.699 total number of trips as origin area, and 422,497 total number of trips as destination area. This area is likely to be either a bus interchange, or a popular bus stop.

```{r}
BusStop_Trips1[BusStop_Trips1$ORIGIN_GRID == 5700,]
```

We noted the bus stop is 46009

```{r}
BusStop[BusStop$BUS_STOP_N == 46009,]
```

From the above, we found out that this bus stop is a Interchange station in Woodlands, a densely populated area.

Similarly, we have also noted a few grids where BOTH incoming and outgoing traffic are relatively high. To draw a similar analysis:

```{r}

list <- intersect(origin_density_map$ORIGIN_GRID[origin_density_map$TOTAL_TRIPS>100000]
        , destin_density_map$DESTIN_GRID[destin_density_map$TOTAL_TRIPS>100000])

```

So we know that the grid with \>100k BOTH incoming and outgoing traffic are:

```{r}
list
```

Next we find out where are these grid:

```{r}
BusStop_hexagon[BusStop_hexagon$grid_id %in% list, "LOC_DESC"]
```

[Insights]{.underline}

Noted these are mainly interchange or MRT station so probably make sense as people may change to bus / train at these spot, and there may also be larger number of buses available in these station.

### Visualization for the Average distance (weighted) taken at Origin and Destination hexagon area

Now we look at the total average weighted distance traveled.

```{r}
summary(origin_density_map)
summary(destin_density_map)
```

We see the mean is around 2500 average distance, and max of around 14,000 distance. As a gauge we will look at data above 8,000 (8km) average distance:

```{r}
tmap_mode("view")
#tmap_options(check.and.fix = TRUE)
map_honeycomb2 = tm_shape(origin_density_map %>%
                         filter(AVERAGE_DIST>8000)) +
  tm_fill(
    col = "AVERAGE_DIST",
    palette = "Reds",
    style = "cont",
    title = "Average Distance by Origin Bus Stop within the Area",
    alpha = 0.4,
    popup.vars = c("Average DISTANCE travelled from this origin bus stop: " = "AVERAGE_DIST"),
    popup.format = list(AVERAGE_DIST = list(format = "f", digits = 0))) +
  tm_borders(col = "grey40", lwd = 0.7)+
  tm_scale_bar()

map_honeycomb3 = tm_shape(destin_density_map %>%
                         filter(AVERAGE_DIST>8000)) +
  tm_fill("AVERAGE_DIST", 
          style = "cont", 
          palette = "Reds",
          title = "Number of Trips by Destination Bus Stop within the Area",
          alpha = 0.4,
          popup.vars = c("Average DISTANCE travelled to this destination bus stop: " = "AVERAGE_DIST"),
          popup.format = list(AVERAGE_DIST = list(format = "f", digits = 0))) +
  tm_borders(col = "grey40", lwd = 0.7)+
  tm_scale_bar()

tmap_arrange(map_honeycomb2, map_honeycomb3, asp=2, ncol=2)
```

```{r}
#FOR THOSE >8km AVERAGE TRAVEL DISTANCE WITH THESE ORIGIN BUS STOP
BusStop_hexagon[BusStop_hexagon$grid_id %in% origin_density_map$ORIGIN_GRID[origin_density_map$AVERAGE_DIST>8000], "LOC_DESC"]
```

```{r}
#FOR THOSE >8km AVERAGE TRAVEL DISTANCE WITH THESE DESTINATION BUS STOP
BusStop_hexagon[BusStop_hexagon$grid_id %in% destin_density_map$DESTIN_GRID[destin_density_map$AVERAGE_DIST>8000], "LOC_DESC"]
```

[Insights]{.underline}

Another interesting observation. For this we will just omit bus stop to and from changi airport, as it can be understood that bus to and from airport are typically of longer distance. The same applies to Changi Naval base/ Opp Changi Naval base as the bus stop is probably serviced by a long distance bus.

The origin bus stops that meet this criteria of \>8km average distance are mainly from woodlands/ yishun / causeway. There are also people taking long distance bus and alight at central/ MBFC /Mapletree / CBD /Seletar / Town area, mainly for work.

### Visualization of OD FLOW

### Creating desire lines

Read the documentation on od2line [here](https://rdrr.io/cran/stplanr/man/od2line.html)

```{r}
simpleBS_hexagon <- left_join(BusStop_Trips, BusStop_hexagon_sf,
                                 by = c("ORIGIN_GRID" = "grid_id")) %>%
  drop_na() %>%
  group_by(ORIGIN_GRID) %>%
  select(8,1) 

simpleBS_hexagon <- unique(simpleBS_hexagon)
simpleBS_hexagon <- st_sf(geometry = simpleBS_hexagon)
```

```{r}

BS_flowLine <- BusStop_Trips1 %>%
  drop_na()  %>%
  group_by(ORIGIN_GRID, DESTIN_GRID) %>% 
  summarize(TOTAL_TRIPS = sum(TRIPS)) %>% 
  filter(TOTAL_TRIPS>1000)
BS_flowLine <- unique(BS_flowLine)
```

```{r}
flowLine <- od2line(flow = BS_flowLine,                     
                    origin_code = "ORIGIN_GRID",                     
                    dest_code = "DESTIN_GRID",                     
                    zones = BusStop_hexagon_sf,                     
                    zone_code = "grid_id") 
```

### Visualising the desire lines

To dive down, we will look at OD visualizatiion for total trips \>1,000 during the timeframe.

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(MPSZ) +   
  tm_polygons() + tm_fill(alpha = 0.1) +
tm_shape(simpleBS_hexagon) +
  tm_polygons() +
flowLine %>%  
tm_shape() +
  tm_lines(lwd = "TOTAL_TRIPS",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

It appears that the highest number of long OD flow is between north and east, ALso noted that the dense activity areas, per the above analysis where we noted the high total trips per origin/destination, are also closley linked as one of the OD flow. These areas are typically the interchange or major stops.

Next we will look at the total trips \>10,000 during the specific period.

```{r}
  
tm_shape(MPSZ) +   
  tm_polygons() + 
tm_shape(simpleBS_hexagon) +
  tm_polygons() +
flowLine %>%  
  filter(TOTAL_TRIPS>10000)%>%
tm_shape() +
  tm_lines(lwd = "TOTAL_TRIPS",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.8)
```

This is quite interesting, as we see the most obvious OD flow is between the woodland checkpoint to woodland interchange / mrt station area. It is also interesting to see there is long distance OD from woodlands to the major Punggol/seletar area.

```{r}
tmap_mode("plot")
```

## Assembling VARIABLES

Next moving on to the assemblling at least three propulsive and three attractiveness variables by using aspatial and geospatial from publicly available sources.

We will look at the following:

1.  Population of Age 7 to 12

2.  School (Primary School) Types

3.  School distinctive programme

4.  HDB Information - Occupancy rate

5.  MPSZ

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

We will focus on age 7 to 12 therefore will remove the other data set, and remove those zero values.

```{r}
pop <- pop %>%
  select(1:3) %>%
  filter(AGE7_12>0)
  
```

This will gives us the PA, SZ, and Total number of Age7_12.

Next we look into the primary school

```{r}
school <- read_csv("data/aspatial/Generalinformationofschools.csv")
```

Note we dont need so many different columns, and we only want to look at primary school:

```{r}
school <- school %>%
  filter(mainlevel_code == "PRIMARY") %>%
  select(1,3:4,10:11,19:31)
```

```{r}
write_rds(school, "data/rds/PrimarySchool.csv") 
```

next will look into the vairous school distinctive programme

```{r}
distinctive <- read_csv("data/aspatial/SchoolDistinctiveProgrammes.csv")
```

we will just look into the alp_domain for all primary school

```{r}
table(distinctive$alp_domain)
```

Combining this to our primary school data

```{r}
primary_school <- left_join(school,distinctive) 
```

There are three school without the corresponding distinctive, this is likely due to the primary school is new, we will confirm on this later. The school database is updated Nov 2023, while the data in distinctive was updated in 2021.

The few distinctive programme will serve as key variables in this dataset.

Next we will go back to pop data set:

```{r}
pop <- left_join(pop, MPSZ, 
                 by =c("SZ" = "SUBZONE_N"))
```

We do the same to the primary school

```{r}
primary_school_MSPZ <- left_join(primary_school, MPSZ, 
                            by =c("dgp_code" = "PLN_AREA_N"))
```

Noted that the data got NA for those dgp_code = SENG KANG, due to discrepencies in format. Therefore we will amend this and rerun

```{r}
primary_school$dgp_code[primary_school$dgp_code == "SENG KANG"] = "SENGKANG"
```

```{r}
primary_school_MSPZ <- left_join(primary_school, MPSZ, 
                            by =c("dgp_code" = "PLN_AREA_N"))%>%
  select(1,4:5,26:27,8,19:23,30)
```

Now we have a primary_school_MSPZ data set that show each primary school, their distinctive programme, and the associated SZ location,and the pop data set that has population aged 7 to 12 by SZ location.

```{r}

write_rds(primary_school_MSPZ, "data/rds/primary_school_MSPZ.csv") 
```

We will look into this later.

## Preparing Origin and Destination Attributes

### Preparing origin attribute

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

```{r}
pop <- pop %>%
  left_join(MPSZ,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

```{r}
mpsz_hexagon <- st_intersection(BusStop_hexagon_sf, MPSZ) %>%
  drop_na()
```

```{r}
flow_data <- left_join(BusStop_Trips1,mpsz_hexagon, 
                       by =c("ORIGIN_GRID" = "grid_id")) %>%
  select(1:10)%>%
  rename(ORIGIN_SZ = SUBZONE_C,
         ORIGIN_SZ_NAME = SUBZONE_N)
  
flow_data <- unique(flow_data)
```

```{r}
flow_data <- left_join(flow_data,mpsz_hexagon, 
                       by =c("DESTIN_GRID" = "grid_id")) %>%
  select(1:12)%>%
  rename(DESTIN_SZ = SUBZONE_C,
         DESTIN_SZ_NAME = SUBZONE_N)
  
flow_data <- unique(flow_data)
```

```{r}
flow_data1 <- flow_data %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

```{r}
flow_data1 <- unique(flow_data1)
```

```{r}
write_rds(flow_data1, "data/rds/SIM_data")
```

## Calibrating Spatial Interaction Models

### Visualising the dependent variable (TRIPS)

```{r}
ggplot(data = flow_data1,
       aes(x = TRIPS)) +
  geom_histogram()
```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = flow_data1,        
       aes(x = dist,            
           y = TRIPS)) +   
  geom_point() +   
  geom_smooth(method = lm)
```

Notice that their relationship hardly resemble linear relationship.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = flow_data1,        
       aes(x = log(dist),            
           y = log(TRIPS))) +   
  geom_point() +   
  geom_smooth(method = lm)
```

### Checking for variables with zero values

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.

In the code chunk below, summary() of Base R is used to compute the summary statistics of all variables:

```{r}
summary(flow_data1)
```

The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

```{r}
flow_data1$DESTIN_AGE7_12 <- ifelse(
  flow_data1$DESTIN_AGE7_12 == 0,
  0.99, flow_data1$DESTIN_AGE7_12)
flow_data1$DESTIN_AGE13_24 <- ifelse(
  flow_data1$DESTIN_AGE13_24 == 0,
  0.99, flow_data1$DESTIN_AGE13_24)
flow_data1$DESTIN_AGE25_64 <- ifelse(
  flow_data1$DESTIN_AGE25_64 == 0,
  0.99, flow_data1$DESTIN_AGE25_64)
flow_data1$ORIGIN_AGE7_12 <- ifelse(
  flow_data1$ORIGIN_AGE7_12 == 0,
  0.99, flow_data1$ORIGIN_AGE7_12)
flow_data1$ORIGIN_AGE13_24 <- ifelse(
  flow_data1$ORIGIN_AGE13_24 == 0,
  0.99, flow_data1$ORIGIN_AGE13_24)
flow_data1$ORIGIN_AGE25_64 <- ifelse(
  flow_data1$ORIGIN_AGE25_64 == 0,
  0.99, flow_data1$ORIGIN_AGE25_64)
```

```{r}
summary(flow_data1)
```

### Origin (Production) constrained SIM

from the summary table above we noted tehre are NA's.

```{r}
flow_data1[is.na(flow_data1$ORIGIN_AGE7_12),]

```

For the purpose of this exercise where we just want data within the specific hexagon areas, we will drop the NA data, and remember to remove the those whiten the same hexagon (dist = 0)

```{r}
flow_data1 <- flow_data1 %>%
  drop_na() %>%
  filter(dist >0)

```

```{r}
summary(flow_data1)
```

### Unconstrained Spatial Interaction Model

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE7_12) + 
                log(DESTIN_AGE7_12) +
                log(dist),
              family = poisson(link = "log"),
              data = flow_data1,
              na.action = na.exclude)
uncSIM
```

### R-squared function

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

### Origin (Production) constrained SIM

```{r}
orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_GRID +
                 log(DESTIN_AGE7_12) +
                 log(dist),
              family = poisson(link = "log"),
              data = flow_data1,
              na.action = na.exclude)
summary(orcSIM)
```

We can examine how the constraints hold for destinations this time

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### Destination constrained

```{r}
decSIM <- glm(formula = TRIPS ~ 
                DESTIN_GRID + 
                log(ORIGIN_AGE7_12) + 
                log(dist),
              family = poisson(link = "log"),
              data = flow_data1,
              na.action = na.exclude)
summary(decSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### Doubly constrained

```{r}
dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_GRID + 
                DESTIN_GRID + 
                log(dist),
              family = poisson(link = "log"),
              data = flow_data1,
              na.action = na.exclude)
summary(dbcSIM)
```

### Model comparison

Using [`compare_performance()`](https://easystats.github.io/performance/reference/compare_performance.html) of [**performance**](https://easystats.github.io/performance/) package

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

This compute the RMSE of all the models in *model_list* file.

The print above reveals that all the SIMs are of similar value.

**Visualising fitted**

We will extract the fitted values from each model, join the values to *data_flow1* data frame, for all the models.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0) 

flow_data1 <- flow_data1 %>% 
  cbind(df) %>% 
  rename(uncTRIPS = "uncSIM$fitted.values")
```

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>% 
  round(digits = 0) 

flow_data1 <- flow_data1 %>% 
  cbind(df) %>% 
  rename(orcTRIPS = "orcSIM$fitted.values")
```

```{r}
df <- as.data.frame(decSIM$fitted.values) %>% 
  round(digits = 0) 

flow_data1 <- flow_data1 %>% 
  cbind(df) %>% 
  rename(decTRIPS = "decSIM$fitted.values")
```

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>% 
  round(digits = 0) 

flow_data1 <- flow_data1 %>% 
  cbind(df) %>% 
  rename(dbcTRIPS = "dbcSIM$fitted.values")
```

Now we plot it:

```{r}


unc_p <- ggplot(data = flow_data1,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = flow_data1,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = flow_data1,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = flow_data1,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```

From the above, we can draw the conclusion that there isnt much of a correlation between the age 7 to 12 population and number of trips across the hexagon areas O/D.

## Future Work - Train Station

```{r}
TrainStation <- st_read(dsn="data/geospatial",                   
                        layer="RapidTransitSystemStation")%>%   
  st_transform(crs = 3414)
```

I see that TrainStation is a Polygon geometry SF with "TYP_CD", "STN_NAM", "TYP_CD_DES", "STN_NAM_DE", and its geometry.

Note that "TYP_CD" is of all 0 value, "STN_NAM" is of all NA value, while "TYP_CD_DES" value is "MRT" or "LRT".

Also note that the above shows a warning message:

```         
Warning: GDAL Message 1: Non closed ring detected. To avoid accepting it, set the OGR_GEOMETRY_ACCEPT_UNCLOSED_RING configuration option to NO
```

```{r}
invalid_geoms <- TrainStation[!st_is_valid(TrainStation), ]
```

It appears to have 3 invalid geoms, apart form the NA entry, we can see that the both "HARBOURFRONT MRT STATION" and "UPPER THOMSON MRT STATION" are the invalid geometries.

For the purpose of this exercise, I will filter out these entries and retain on the valid geometries in TrainStation.

```{r}
TrainStation <- TrainStation[st_is_valid(TrainStation), ]%>%   
  st_transform(crs = 3414)
```

```{r}
TrainStation_Exit <- st_read(dsn="data/geospatial",                 
                             layer="Train_Station_Exit_Layer")%>%   
  st_transform(crs = 3414)


```

I see that TrainStation_Exit is a Point geometry SF with "stn_name", "exit_code", and its geometry.

I get aspatial Data of PASSENGER VOLUME BY ORIGIN DESTINATION TRAIN STATIONS, downloaded via API (postman GET) from Data Mall LTA. For the purpose of this exercise the Aug 2023 Data will be used.

```{r}
OD_train <- read_csv("data/aspatial/origin_destination_train_202308.csv") #non-spatial data with no geometry features
```

```{r}
OD_train$ORIGIN_PT_CODE <- as.factor(OD_train$ORIGIN_PT_CODE)
OD_train$DESTINATION_PT_CODE <- as.factor(OD_train$DESTINATION_PT_CODE)
```

Noted that both the aspatial data, for bus and train, are similar where there are total of 7 columns YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS.

We will now first combine the SF data sources relating to Bus Stop, using `st_intersection():`

```{r}
TrainStation_combined <- st_intersection(TrainStation, MPSZ)
```

Before proceeding it will be good practice to check the crs of each using st_crs.

We will now first combine the SF data sources relating to Train Station, using `st_intersection():`

```{r}
TrainStation_combined <- st_intersection(TrainStation_combined, TrainStation_Exit) %>%
  mutate(STN_NAM_DE = str_replace(STN_NAM_DE, "MRT STATION", "")) %>%
  mutate(STN_NAM_DE = str_replace(STN_NAM_DE, "LRT STATION", ""))%>%
  select(3:13) %>%
  mutate(STN_NAM_DE = str_trim(STN_NAM_DE))

```

Note this data frame does not include the two MRT stations we filtered out earlier.

Note that we have removed the first two column (NA and 0 values), in order to associate the train station code, we will import the following data set and join them:

```{r}
TrainStation_Code <- readxl::read_excel("data/aspatial/Train Station Codes and Chinese Names.xls")

TrainStation_Code$mrt_station_english <- toupper(TrainStation_Code$mrt_station_english)
```

```{r}
TrainStation_combined <- left_join(TrainStation_combined, 
                              TrainStation_Code, 
                              by = c("STN_NAM_DE" = "mrt_station_english"))
  
```

For reproducibility, will save into a rds file:

```{r}
write_rds(TrainStation_combined, "data/rds/TrainStation_combined.csv")  
```

Next, we are going to append the planning subzone code from TrainStation_combined data frame onto OD_train data frame.

```{r}
Origin_TrainStation <- left_join(OD_train , TrainStation_combined,
            by = c("ORIGIN_PT_CODE" = "stn_code")) %>%
  select(1:11,16) 

```

Looking at the results, noted there are a number of mismatches due to the origin PT code having multiple values. We will need to look into this and clean up the dataset for better visualiztion.

```{r}
OD_train_filter <- OD_train %>%
  mutate(ORIGIN_PT_CODE = str_replace(ORIGIN_PT_CODE, "/.*", "")) %>%
  mutate(DESTINATION_PT_CODE = str_replace(DESTINATION_PT_CODE, "/.*", ""))
```

This removes the additional train codes with multiple lines (e.g. Botanic Garden is both Circle line and Downtown line), and only retain one, so to avoid double counting. Then we run the left_join using this dataframe:

```{r}
Origin_TrainStation_filter <- left_join(OD_train_filter , TrainStation_combined,
            by = c("ORIGIN_PT_CODE" = "stn_code")) %>%
  select(1:11,16) 
```

## Own Notes

Constructing an O/D Matrix

-   In O/D matrix, the Ti sum of row representing total output of origin location, while sum of column represents input of destination.

-   Can have sub-matrix

-   Additional new activity may change this to new structure

-   O/D Matrix can be costly, 322 x 322 = 110k O/D pairs, which each info need to be carefully provided (but may also change).

-   GPS/ Smart card can collect personal info to represent flows between locations

There are 3 Spatial Interaction Models (First 2 steps)

-   Basic assumption is that function of attributes of location of origin and destination and frictions

-   Potential Model is usually for measuring accessibility

-   Retail model usually used for franchise to choose service area of store of delivery segment

-   This course we will focus on Gravity Model which is the most common model. It uses Newton first law of gravity. Estimated Tij is transition/trip or flow between origin i (row) and destination j(columns). Parameters V, W, d, k lamda, alpha and beta. Beta is always assumed to be negative as increase in cost.distance will likely decrease the interaction.

-   A family of gravity Models - Unconstrained (totally constrained), origin constrained, destination constrained, doubly constrained.

We can see that ***sp*** is in list, no geometric column, they are segregated as different table inside object, In tidyverse it is in a whole table. But to call a field in ***sp***, we will need to write something like below

```         
  select(mpsz@data$SUBZONE) 
```
