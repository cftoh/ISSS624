---
title: "In-Class Exercise 3: Spatial Interaction Models: Calibrating Spatial Interaction Models with R"
date: "2 December 2023"
date-modified:  "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning:  false
---

Learning Source: <https://r4gdsa.netlify.app/chap16#overview>

This is flow data (interaction) from one location to another, although we typically only look at tangible ones, there are also intangibles ones like telco etc.

In Class Note:

-   some busstop is in Johor (Msia), which is not covered in mpsz. Therefore we are not using mpsz planning subzone to define the hexagon. mpsz is also contiguous (joint each other), where analytical hexagon is not joint together. -\> This allow us to apply various spatial weights method onto different context.

-   Trade Area analysis (Spatial Interaction Model) - on retail marketing

-   Note that not all relationship is linear, so we do not just look into linear regressions.

To get started, in this ICE we can look into Gravity Model (per lecture deck).

First load the library :

```{r}
pacman::p_load(tmap, sf, sp, DT,
               performance, reshape2,
               ggpubr, tidyverse)
```

Note that ***sp*** is an older R package that is replaced by sf. sp allows us to handle spatial data in spatial polygon/point/line data frame, is a delegate function to store data, for efficiency in computational power. ***reshape2*** is old version of tidyR, developed by the same person, to do pivoting etc, but this able to handle matrix which tidyverse does not (coz tidyverse everything is in dataframe). Also note tidyverse has got those related packages e.g. ggplot2 (tidyverse.org), so not load things unnecessary,

Next we look at the data (used in HOE 6):

-   *od_data.rds*, weekday morning peak passenger flows at planning subzone level.

-   *mpsz.rds*, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

## Computing Distance Matrix

Within the zone we might have different busstop, so we can use centroid as a way to calibrate, or maybe using mean center etc.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```

Notice that it is already in SF format (coz we saved in rds previously)

Next we convert it to SP format (spacial polygon), [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) will be used to convert *mpsz* from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.

```{r}
mpsz_sp <- as(mpsz, "Spatial")

#Another tidy way of writing the code is below:
#mpsz_sp <- mpsz %>%
#  as.Spatial()

mpsz_sp
```

We can see that ***sp*** is in list, no geometric column, they are segregated as different table inside object, In tidyverse it is in a whole table. But to call a field in ***sp***, we will need to write something like below

```{mpsz_sp_selected <- mpsz_sp %>%}
  select(mpsz@data$SUBZONE)

```

mpsz is highest level object name, need to call the specific table and the data field.

### Computing the distance matrix

We use the spDists() coz faster.

```{r}
dist <- spDists(mpsz_sp, 
                longlat = FALSE) #because or subzone is already svr21, already got unit. If not it will treat data as x and y, then calculate great circle distance.

head(dist, n=c(10, 10)) #only list first 10 col and 10 rows

```

### Labelling column and row heanders of a distance matrix

First, we will create a list sorted according to the the distance matrix by planning sub-zone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next we will attach `SUBZONE_C` to row and column for distance matrix matching ahead

```{r}
colnames(dist) <- paste0(sz_names) 
rownames(dist) <- paste0(sz_names)
```

### Pivoting distance value by SUBZONE_C

Next, we will pivot the distance matrix into a long table by using the
row and column subzone codes as show in the code chunk below.

```{r}
distPair <- melt(dist) %>% #this is a old reshape tool function, that take dist matrxi and convert it to long table, 1. origin, 2. destination, 3. distance matrix
  rename(dist = value)
head(distPair, 10)
```

Notice that the within zone distance is 0.

**NEVER sort the data, coz we need to maintain sequence.**

### Updating intra-zonal distances

In this section, we are going to append a constant value to replace the intra-zonal distance of 0.

First, we will select and find out the minimum value of the distance by using `summary()`.

```{r}
#this code is just to reveal result, no output
distPair %>%
  filter(dist > 0) %>% #this is to check the minimal distance i have
  summary()
#to calculate intrazonal (this is extra, we can avoid not using it at all)
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

The code chunk below will be used to check the result data.frame.

```{r}
distPair %>%
  summary()
```

The code chunk below is used to rename the origin and destination fields.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

Lastly, the code chunk below is used to save the dataframe for future use.

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

## Preparing flow data

```{r}
od_data <- read_rds("data/rds/od_data.rds")
```

Next, we will compute the total passenger trip between and within
planning subzones by using the code chunk below. The output is all *flow_data*.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 

head(flow_data, 10)
```

### Separating intra-flow from passenger volume df

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

###  Combining passenger volume data with distance value

Before we can join *flow_data* and *distPair*, we need to convert data value type of *ORIGIN_SZ* and *DESTIN_SZ* fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

Now, `left_join()` of **dplyr** will be used to *flow_data* dataframe and *distPair* dataframe. The output is called *flow_data1*.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## Preparing Origin and Destination Attributes

### Importing population data

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

### Geospatial data wrangling

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)

```

### Preparing origin attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### Preparing destination attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

```{r}
write_rds(flow_data1, "data/rds/SIM_data")
```

## Calibrating Spatial Interaction Models

###  Importing the modelling data

```{r}
SIM_data <- read_rds("data/rds/SIM_data.rds")
```

### Visualising the dependent variable

Firstly, let us plot the distribution of the dependent variable
(i.e.Â TRIPS) by using histogram method by using the code chunk below.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,        
       aes(x = dist,            
           y = TRIPS)) +   
  geom_point() +   
  geom_smooth(method = lm)
```

Notice that their relationship hardly resemble linear relationship.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = SIM_data,        
       aes(x = log(dist),            
           y = log(TRIPS))) +   
  geom_point() +   
  geom_smooth(method = lm)
```

### Checking for variables with zero values

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.

In the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in *SIM_data* data frame.

```{r}
summary(SIM_data)
```

The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

```{r}
SIM_data$DESTIN_AGE7_12 <- ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 <- ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 <- ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 <- ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 <- ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 <- ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)
```

```{r}
summary(SIM_data)
```

Notice that all the 0 values have been replaced by 0.99.

### Unconstrained Spatial Interaction Model

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM
```

###  R-squared function

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

### Origin (Production) constrained SIM

```{r}
orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(orcSIM)
```

We can examine how the constraints hold for destinations this time

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### Destination constrained

```{r}
decSIM <- glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(decSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### Doubly constrained

```{r}
dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(dbcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

### Model comparison

Another useful model performance measure for continuous dependent variable is [Root Mean Squared Error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e). In this sub-section, you will learn how to use [`compare_performance()`](https://easystats.github.io/performance/reference/compare_performance.html) of [**performance**](https://easystats.github.io/performance/) package

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

Next, we will compute the RMSE of all the models in *model_list* file

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

###  Visualising fitted

Firstly we will extract the fitted values from each model by using the code chunk below.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

Next, we will join the values to *SIM_data* data frame.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

Repeat the same step by for Origin Constrained SIM (i.e.Â orcSIM)

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")
```

Repeat the same step by for Destination Constrained SIM (i.e.Â decSIM)

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")
```

Repeat the same step by for Doubly Constrained SIM (i.e.Â dbcSIM)

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")

unc_p <- ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
